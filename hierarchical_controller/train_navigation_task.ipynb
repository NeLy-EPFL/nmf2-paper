{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pkg_resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "import stable_baselines3 as sb3\n",
    "import stable_baselines3.common.logger as logger\n",
    "import stable_baselines3.common.callbacks as callbacks\n",
    "import stable_baselines3.common.env_checker as env_checker\n",
    "from dm_control import mjcf\n",
    "from dm_control.rl.control import PhysicsError\n",
    "import imageio\n",
    "import scipy.spatial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric as pyg\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric.loader as pyg_loader\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Callable, Optional, List, Union\n",
    "from tqdm import trange\n",
    "from dm_control.rl.control import PhysicsError\n",
    "from PIL import Image\n",
    "\n",
    "from flygym.arena.mujoco_arena import FlatTerrain\n",
    "from flygym.envs.nmf_mujoco import NeuroMechFlyMuJoCo, MuJoCoParameters\n",
    "from flygym.state import stretched_pose\n",
    "import flygym.util.vision as vision\n",
    "import flygym.util.config as config\n",
    "from flygym.arena import BaseArena\n",
    "from flygym.arena.mujoco_arena import OdorArena, FlatTerrain, GappedTerrain, BlocksTerrain\n",
    "from flygym.util.data import color_cycle_rgb\n",
    "\n",
    "from rl_navigation import ObstacleOdorArena, NMFNavigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check on MDP task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_arena = FlatTerrain(ground_alpha=1)\n",
    "arena = ObstacleOdorArena(\n",
    "    terrain=terrain_arena,\n",
    "    obstacle_positions=np.array([(7.5, 0)]),\n",
    "    obstacle_radius=1,\n",
    "    odor_source=np.array([[15, 0, 2]]),\n",
    "    marker_size=0.5,\n",
    "    obstacle_colors=(0, 0, 0, 1),\n",
    ")\n",
    "sim = NMFNavigation(\n",
    "    arena=arena,\n",
    "    test_mode=True,\n",
    "    debug_mode=True,\n",
    "    decision_dt=0.1,\n",
    ")\n",
    "# env_checker.check_env(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.reset()\n",
    "for i in trange(30):\n",
    "    obs, reward, terminated, truncated, info = sim.step(np.array([0]))\n",
    "    if terminated:\n",
    "        print(\"Terminated\")\n",
    "        break\n",
    "sim.save_video(\"test.mp4\", stabilization_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    terrain_arena = FlatTerrain(ground_alpha=1)\n",
    "    arena = ObstacleOdorArena(\n",
    "        terrain=terrain_arena,\n",
    "        obstacle_positions=np.array([(7.5, 0)]),\n",
    "        obstacle_radius=1,\n",
    "        odor_source=np.array([[15, 0, 2]]),\n",
    "        marker_size=0.5,\n",
    "        obstacle_colors=(0, 0, 0, 1),\n",
    "    )\n",
    "    sim = NMFNavigation(\n",
    "        arena=arena,\n",
    "        test_mode=False,\n",
    "        debug_mode=False,\n",
    "    )\n",
    "    return sim\n",
    "\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "num_procs = 12\n",
    "# vec_env = SubprocVecEnv([make_env for i in range(num_procs)])\n",
    "vec_env = make_vec_env(make_env, n_envs=num_procs, vec_env_cls=SubprocVecEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# terrain_arena = FlatTerrain(ground_alpha=1)\n",
    "# arena = ObstacleOdorArena(\n",
    "#     terrain=terrain_arena,\n",
    "#     obstacle_positions=np.array([(7.5, 1.5), (12.5, -1.5)]),\n",
    "#     odor_source=np.array([[20, 0, 2]]),\n",
    "#     marker_size=0.5,\n",
    "#     obstacle_colors=(0.14, 0.14, 0.2, 1),\n",
    "# )\n",
    "# sim = NMFNavigation(\n",
    "#     arena=arena,\n",
    "#     test_mode=False,\n",
    "# )\n",
    "# env_checker.check_env(sim)\n",
    "\n",
    "np.random.seed(0)\n",
    "sb3.common.utils.set_random_seed(0, using_cuda=True)\n",
    "\n",
    "start_from = \"logs/trial_17b/trial_17b_199200_steps.zip\"\n",
    "# start_from = None\n",
    "train = True\n",
    "\n",
    "log_dir = \"logs/trial_17c\"\n",
    "checkpoint_callback = callbacks.CheckpointCallback(\n",
    "    save_freq=100,\n",
    "    save_path=log_dir,\n",
    "    name_prefix=\"trial_17c\",\n",
    "    save_replay_buffer=True,\n",
    "    save_vecnormalize=True,\n",
    "    verbose=2,\n",
    ")\n",
    "my_logger = logger.configure(log_dir, [\"tensorboard\", \"stdout\", \"csv\"])\n",
    "if start_from is None:\n",
    "    model = sb3.SAC(\n",
    "        \"MlpPolicy\",\n",
    "        # env=sim,\n",
    "        env=vec_env,\n",
    "        policy_kwargs={\"net_arch\": [16, 16]},\n",
    "        verbose=2,\n",
    "        learning_rate=0.01,\n",
    "    )\n",
    "else:\n",
    "    model = sb3.SAC.load(start_from)\n",
    "    model.set_env(vec_env)\n",
    "    print(model.verbose, model.learning_rate, model.policy_kwargs)\n",
    "model.set_logger(my_logger)\n",
    "\n",
    "if train:\n",
    "    model.learn(total_timesteps=200_000, progress_bar=True, callback=checkpoint_callback)\n",
    "    model.save(\"models/trial_17c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
