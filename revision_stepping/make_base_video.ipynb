{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sleap \n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data\")\n",
    "prism_labels = sleap.io.dataset.load_file(str(data_folder/\"best_side.slp\"))\n",
    "ventral_labels = sleap.io.dataset.load_file(str(data_folder/\"best_ventral.slp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "step_data_stance_swing_path = Path(\"/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/revision_new_step_PR_bestdata_fly001_trial001subset_video_4_start5751_end6001_stepping.txt\")\n",
    "video_start_frame = 5751\n",
    "video_end_frame = 6001\n",
    "\n",
    "start, end = None, None\n",
    "swing_stance_dict = {}\n",
    "with open(step_data_stance_swing_path, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Start\"):\n",
    "            start = int(line.split(\" \")[1])\n",
    "        if line.startswith(\"End\"):\n",
    "            end = int(line.split(\" \")[1])\n",
    "        if line in [\"RF\", \"RM\", \"RH\", \"LF\", \"LM\", \"LH\"]:\n",
    "            assert start is not None and end is not None, \"Start and end not defined\"\n",
    "            leg = line\n",
    "            swing_stance_dict[leg] = {}\n",
    "        if \"swing\" in line or \"stance\" in line:\n",
    "            phase = line.split(\" \")[0]\n",
    "            indexes = np.array(line.split(\" \")[1:]).astype(int)\n",
    "            assert np.all(indexes >= start-1) and np.all(indexes <= end+1), \"Indexes not in range\"\n",
    "            indexes -= start\n",
    "            if phase == \"swing\":\n",
    "                # the frames in the file are the ones were the first elevation \n",
    "                #is observed but really the swing starts inbeetween the two frames\n",
    "                # This gives some margin for the adhesion\n",
    "                indexes -= 1\n",
    "            # save as integers\n",
    "            swing_stance_dict[leg][phase] = indexes\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "# put in video indexes\n",
    "for leg, phases in swing_stance_dict.items():\n",
    "    for phase, indexes in phases.items():\n",
    "        swing_stance_dict[leg][phase] = indexes + start - video_start_frame\n",
    "\n",
    "\n",
    "with open(\"/Users/stimpfli/Desktop/flygym_other/flygym/data/behavior/single_steps_untethered.pkl\", \"rb\") as f:\n",
    "    single_steps_data = pickle.load(f)\n",
    "\n",
    "single_steps_name = single_steps_data[\"meta\"][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': [35, 51], 'RM': [39, 56], 'LH': [41, 57]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frontleg, frontleg_id, midleg, midleg_id, hindleg, hindleg_id = single_steps_data[\"meta\"][\"name\"].split(\"_\")\n",
    "leg_step_ids = {}\n",
    "for leg, id in zip([frontleg, midleg, hindleg], [frontleg_id, midleg_id, hindleg_id]):\n",
    "    index = int(id[0])\n",
    "    state = id[1:]\n",
    "    leg_step_ids[leg] = [swing_stance_dict[leg][state][index], swing_stance_dict[leg][state][index+1]]\n",
    "leg_step_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in [\"V-F-Claw\", \"V-M-Claw\", \"V-H-Claw\"]:\n",
    "    prism_labels.skeleton.delete_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_skeletons = {}\n",
    "v_skeletons = {}\n",
    "for leg in leg_step_ids:\n",
    "    sleg_skel = sleap.skeleton.Skeleton()\n",
    "    leg_id = leg[1]+\"-\"\n",
    "    for node in prism_labels.skeleton.nodes:\n",
    "        if leg_id in node.name:\n",
    "            sleg_skel.add_node(node.name)\n",
    "    \n",
    "    for edge in prism_labels.skeleton.edges:\n",
    "        if leg_id in edge[0].name and leg_id in edge[1].name:\n",
    "            sleg_skel.add_edge(edge[0].name, edge[1].name)\n",
    "    \n",
    "    s_skeletons[leg] = sleg_skel\n",
    "\n",
    "    vleg_skel = sleap.skeleton.Skeleton()\n",
    "    for node in ventral_labels.skeleton.nodes:\n",
    "        if leg in node.name:\n",
    "            vleg_skel.add_node(node.name)\n",
    "    \n",
    "    for edge in ventral_labels.skeleton.edges:\n",
    "        if leg in edge[0].name and leg in edge[1].name:\n",
    "            vleg_skel.add_edge(edge[0].name, edge[1].name)\n",
    "    \n",
    "    v_skeletons[leg] = vleg_skel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RF': Skeleton(name='Skeleton-4', description='None', nodes=['RF-ThC', 'RF-CTr', 'RF-FTi', 'RF-TiTa', 'RF-Claw'], edges=[('RF-ThC', 'RF-CTr'), ('RF-CTr', 'RF-FTi'), ('RF-FTi', 'RF-TiTa'), ('RF-TiTa', 'RF-Claw')], symmetries=[]),\n",
       " 'RM': Skeleton(name='Skeleton-6', description='None', nodes=['RM-ThC', 'RM-CTr', 'RM-FTi', 'RM-TiTa', 'RM-Claw'], edges=[('RM-ThC', 'RM-CTr'), ('RM-CTr', 'RM-FTi'), ('RM-FTi', 'RM-TiTa'), ('RM-TiTa', 'RM-Claw')], symmetries=[]),\n",
       " 'LH': Skeleton(name='Skeleton-8', description='None', nodes=['LH-ThC', 'LH-CTr', 'LH-FTi', 'LH-TiTa', 'LH-Claw'], edges=[('LH-ThC', 'LH-CTr'), ('LH-CTr', 'LH-FTi'), ('LH-FTi', 'LH-TiTa'), ('LH-TiTa', 'LH-Claw')], symmetries=[])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_skeletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Node(name='He', weight=1.0),\n",
       " Node(name='Th', weight=1.0),\n",
       " Node(name='Abd', weight=1.0),\n",
       " Node(name='LF-ThC', weight=1.0),\n",
       " Node(name='LF-CTr', weight=1.0),\n",
       " Node(name='LF-FTi', weight=1.0),\n",
       " Node(name='LF-TiTa', weight=1.0),\n",
       " Node(name='LF-Claw', weight=1.0),\n",
       " Node(name='LM-ThC', weight=1.0),\n",
       " Node(name='LM-CTr', weight=1.0),\n",
       " Node(name='LM-FTi', weight=1.0),\n",
       " Node(name='LM-TiTa', weight=1.0),\n",
       " Node(name='LM-Claw', weight=1.0),\n",
       " Node(name='LH-ThC', weight=1.0),\n",
       " Node(name='LH-CTr', weight=1.0),\n",
       " Node(name='LH-FTi', weight=1.0),\n",
       " Node(name='LH-TiTa', weight=1.0),\n",
       " Node(name='LH-Claw', weight=1.0),\n",
       " Node(name='RH-ThC', weight=1.0),\n",
       " Node(name='RH-CTr', weight=1.0),\n",
       " Node(name='RH-FTi', weight=1.0),\n",
       " Node(name='RH-TiTa', weight=1.0),\n",
       " Node(name='RH-Claw', weight=1.0),\n",
       " Node(name='RM-ThC', weight=1.0),\n",
       " Node(name='RM-CTr', weight=1.0),\n",
       " Node(name='RM-FTi', weight=1.0),\n",
       " Node(name='RM-TiTa', weight=1.0),\n",
       " Node(name='RM-Claw', weight=1.0),\n",
       " Node(name='RF-ThC', weight=1.0),\n",
       " Node(name='RF-CTr', weight=1.0),\n",
       " Node(name='RF-FTi', weight=1.0),\n",
       " Node(name='RF-TiTa', weight=1.0),\n",
       " Node(name='RF-Claw', weight=1.0),\n",
       " Node(name='LA', weight=1.0),\n",
       " Node(name='RA', weight=1.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventral_labels.skeleton.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_out_path = data_folder / \"labelled_frames\"\n",
    "frame_out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# remove all images from the folder\n",
    "for file in os.listdir(frame_out_path):\n",
    "    os.remove(os.path.join(frame_out_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = plt.cm.tab20.colors[1]\n",
    "leg_color = plt.cm.tab20.colors[6]\n",
    "\n",
    "# right on the top\n",
    "vid_len, height, width , _ = prism_labels.video.shape\n",
    "half_height = height // 2\n",
    "reduction_factor = 100\n",
    "figure_size = (np.round(height/reduction_factor).astype(int), np.round(width/reduction_factor).astype(int))\n",
    "\n",
    "lw, ms = 3.0, 10.0\n",
    "\n",
    "frames_with_instance = []\n",
    "\n",
    "for i, (frame_side, frame_ventral) in enumerate(zip(prism_labels.labeled_frames, ventral_labels.labeled_frames)):\n",
    "    assert np.all(frame_side.image == frame_ventral.image), \"Frame are not matching\"\n",
    "\n",
    "    image = frame_side.image\n",
    "    # instances might be empty\n",
    "    plt.figure(figsize=(40, 20), dpi=100)\n",
    "    plt.imshow(image, cmap=\"gray\", origin='upper')\n",
    "    if frame_side.user_instances and frame_ventral.user_instances:\n",
    "        for instance in frame_side.user_instances:\n",
    "            sleap.nn.viz.plot_instance(instance, cmap=[color], lw=lw, ms=ms)\n",
    "            for leg, skel in s_skeletons.items():\n",
    "                if i > leg_step_ids[leg][0] and i < leg_step_ids[leg][1]:\n",
    "                    if leg[0] == \"L\":\n",
    "                        if np.all(instance.numpy()[:, 1] < half_height):\n",
    "                            sleap.nn.viz.plot_instance(instance, skeleton=skel, cmap=[leg_color], lw=lw, ms=ms)\n",
    "                    elif leg[0] == \"R\":\n",
    "                        if np.all(instance.numpy()[:, 1] > half_height):\n",
    "                            sleap.nn.viz.plot_instance(instance, skeleton=skel, cmap=[leg_color], lw=lw, ms=ms)\n",
    "        \n",
    "        for instance in frame_ventral.user_instances:\n",
    "            sleap.nn.viz.plot_instance(instance, cmap=[color], lw=lw, ms=ms)\n",
    "            for leg, skel in v_skeletons.items():\n",
    "                if i > leg_step_ids[leg][0] and i < leg_step_ids[leg][1]:\n",
    "                    sleap.nn.viz.plot_instance(instance, skeleton=skel, cmap=[leg_color], lw=lw, ms=ms)\n",
    "        \n",
    "        frames_with_instance.append(i)\n",
    "    \n",
    "    # save the image without margins\n",
    "    plt.ylim(55, height-55)\n",
    "    plt.xlim(451, width-450)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(frame_out_path / f\"frame_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# now read each of those images and stack the right 3d pose next to it\n",
    "pose3d_path = Path(\"/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/seqikpy_output/aligned_pose/\")\n",
    "pose3d_images_paths = list(pose3d_path.glob(\"azim_30_elev_30_*.png\"))\n",
    "\n",
    "pose_frame = cv2.imread(str(pose3d_images_paths[0]))\n",
    "pose_height, pose_width = pose_frame.shape[:2]\n",
    "frame_height, frame_width = cv2.imread(str(frame_out_path / \"frame_0.png\")).shape[:2]\n",
    "\n",
    "if pose_height < frame_height:\n",
    "    resize_factor = frame_height/pose_height\n",
    "    resized_pose_frame = cv2.resize(pose_frame, (0,0), fx=resize_factor, fy=resize_factor)\n",
    "    black_square_height, black_square_width = resized_pose_frame.shape[:2]\n",
    "else:\n",
    "    black_square_height, black_square_width = frame_height, pose_width\n",
    "\n",
    "\n",
    "height_diff = (frame_height - pose_height)//2\n",
    "\n",
    "output_path_pose = data_folder / \"labelled_frames_w3dpose\"\n",
    "output_path_pose.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "conversion_factor = len(frames_with_instance)/len(pose3d_images_paths)\n",
    "\n",
    "for i in range(vid_len):\n",
    "    base_frame = cv2.imread(str(frame_out_path / f\"frame_{i}.png\"))\n",
    "    if i in frames_with_instance:\n",
    "        pose3d_index = np.round((i-frames_with_instance[0])/conversion_factor).astype(int)\n",
    "        pose3d_frame = cv2.imread(str(pose3d_path / f\"azim_30_elev_30_{pose3d_index}.png\"))\n",
    "        if pose_height < frame_height:\n",
    "            # resize both axis\n",
    "            pose3d_frame = cv2.resize(pose3d_frame, (0,0), fx=resize_factor, fy=resize_factor)\n",
    "        else:\n",
    "            pose3d_frame = pose3d_frame[height_diff:height_diff+frame_height, :, :]\n",
    "    else:\n",
    "        pose3d_frame = np.zeros((black_square_height, black_square_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    combined = np.concatenate([base_frame, pose3d_frame], axis=1)\n",
    "    cv2.imwrite(str(output_path_pose / f\"frame_{i}.png\"), combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with clang version 14.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/labelled_frames/frame_%d.png':\n",
      "  Duration: 00:00:07.17, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 2334x1970 [SAR 3937:3937 DAR 1167:985], 12 fps, 12 tbr, 12 tbn, 12 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x154010e00] using SAR=1/1\n",
      "[libx264 @ 0x154010e00] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x154010e00] profile High, level 5.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x154010e00] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=12 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=25.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/labelled_frames_annotated.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 2334x1970 [SAR 1:1 DAR 1167:985], q=2-31, 12 fps, 12288 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   86 fps= 22 q=-1.0 Lsize=    2192kB time=00:00:06.91 bitrate=2596.3kbits/s speed=1.74x    \n",
      "video:2190kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.086590%\n",
      "[libx264 @ 0x154010e00] frame I:1     Avg QP:19.75  size: 50370\n",
      "[libx264 @ 0x154010e00] frame P:22    Avg QP:21.11  size: 38269\n",
      "[libx264 @ 0x154010e00] frame B:63    Avg QP:22.47  size: 21425\n",
      "[libx264 @ 0x154010e00] consecutive B-frames:  2.3%  0.0%  0.0% 97.7%\n",
      "[libx264 @ 0x154010e00] mb I  I16..4: 17.0% 79.3%  3.7%\n",
      "[libx264 @ 0x154010e00] mb P  I16..4:  3.2% 10.7%  0.8%  P16..4: 33.4%  6.6%  2.2%  0.0%  0.0%    skip:43.2%\n",
      "[libx264 @ 0x154010e00] mb B  I16..4:  0.6%  1.2%  0.1%  B16..8: 37.3%  4.3%  0.5%  direct: 1.0%  skip:54.9%  L0:42.9% L1:55.6% BI: 1.5%\n",
      "[libx264 @ 0x154010e00] 8x8 transform intra:72.5% inter:92.5%\n",
      "[libx264 @ 0x154010e00] coded y,uvDC,uvAC intra: 33.0% 4.1% 3.8% inter: 8.3% 0.2% 0.1%\n",
      "[libx264 @ 0x154010e00] i16 v,h,dc,p: 26% 46%  7% 20%\n",
      "[libx264 @ 0x154010e00] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 20% 33%  3%  5%  5%  6%  3%  4%\n",
      "[libx264 @ 0x154010e00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 21% 23% 18%  5%  9%  7%  7%  5%  4%\n",
      "[libx264 @ 0x154010e00] i8c dc,h,v,p: 96%  2%  2%  0%\n",
      "[libx264 @ 0x154010e00] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x154010e00] ref P L0: 68.2%  7.9% 16.4%  7.5%\n",
      "[libx264 @ 0x154010e00] ref B L0: 83.6% 12.5%  3.8%\n",
      "[libx264 @ 0x154010e00] ref B L1: 94.1%  5.9%\n",
      "[libx264 @ 0x154010e00] kb/s:2502.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video out of the images using ffmpeg\n",
    "video_out_path = data_folder / \"labelled_frames_annotated.mp4\"\n",
    "# 12 fps = 10x reduction\n",
    "# frame numbering is 1-indexed\n",
    "\n",
    "os.system(f\"ffmpeg -y -r 12 -f image2 -s {figure_size[1]}x{figure_size[0]} -i {frame_out_path / 'frame_%d.png'} -vcodec libx264 -crf 25 -pix_fmt yuv420p {video_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with clang version 14.0.6\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-avresample --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1671040356584/_build_env/bin/pkg-config\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/labelled_frames_w3dpose/frame_%d.png':\n",
      "  Duration: 00:00:07.17, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc), 4304x1970, 12 fps, 12 tbr, 12 tbn, 12 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x118809400] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x118809400] profile High, level 5.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x118809400] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=12 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=25.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/Users/stimpfli/Desktop/nmf2-paper/revision_stepping/data/labelled_frames_annotated_w3dpose.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 4304x1970, q=2-31, 12 fps, 12288 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   86 fps= 14 q=-1.0 Lsize=    2387kB time=00:00:06.91 bitrate=2827.5kbits/s speed=1.15x    \n",
      "video:2385kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.078806%\n",
      "[libx264 @ 0x118809400] frame I:1     Avg QP:20.85  size: 52030\n",
      "[libx264 @ 0x118809400] frame P:22    Avg QP:21.62  size: 41788\n",
      "[libx264 @ 0x118809400] frame B:63    Avg QP:22.97  size: 23344\n",
      "[libx264 @ 0x118809400] consecutive B-frames:  2.3%  0.0%  0.0% 97.7%\n",
      "[libx264 @ 0x118809400] mb I  I16..4:  9.1% 88.6%  2.3%\n",
      "[libx264 @ 0x118809400] mb P  I16..4:  1.8%  6.4%  0.6%  P16..4: 18.5%  3.7%  1.3%  0.0%  0.0%    skip:67.7%\n",
      "[libx264 @ 0x118809400] mb B  I16..4:  0.3%  0.7%  0.1%  B16..8: 21.0%  2.6%  0.3%  direct: 0.5%  skip:74.4%  L0:43.5% L1:54.9% BI: 1.7%\n",
      "[libx264 @ 0x118809400] 8x8 transform intra:75.2% inter:91.8%\n",
      "[libx264 @ 0x118809400] coded y,uvDC,uvAC intra: 28.5% 5.7% 5.3% inter: 4.5% 0.2% 0.1%\n",
      "[libx264 @ 0x118809400] i16 v,h,dc,p: 30% 44%  7% 19%\n",
      "[libx264 @ 0x118809400] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 16% 29%  2%  4%  4%  5%  3%  3%\n",
      "[libx264 @ 0x118809400] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 21% 22%  4%  8%  7%  7%  4%  4%\n",
      "[libx264 @ 0x118809400] i8c dc,h,v,p: 95%  2%  3%  0%\n",
      "[libx264 @ 0x118809400] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x118809400] ref P L0: 68.3%  7.8% 16.3%  7.5%\n",
      "[libx264 @ 0x118809400] ref B L0: 83.8% 12.5%  3.7%\n",
      "[libx264 @ 0x118809400] ref B L1: 94.1%  5.9%\n",
      "[libx264 @ 0x118809400] kb/s:2725.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video out of the images using ffmpeg\n",
    "video_out_path = data_folder / \"labelled_frames_annotated_w3dpose.mp4\"\n",
    "# 12 fps = 10x reduction\n",
    "\n",
    "os.system(f\"ffmpeg -y -r 12 -f image2 -s {figure_size[1]}x{figure_size[0]} -i {output_path_pose / 'frame_%d.png'} -vcodec libx264 -crf 25 -pix_fmt yuv420p {video_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
